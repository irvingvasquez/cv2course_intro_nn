{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal Multicapa\n",
    "\n",
    "Una red neuronal multicapa tiene capas ocultas entre la entrada y la salida. A este tipo de red también se le conoce como perceptrón multicapa (MLP por sus siglas en inglés)\n",
    "\n",
    "En este ejercicio crearemos una red neuronal multicapa. \n",
    "\n",
    "@juan1rving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos paquetes\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones necesarias\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Función sigmoide\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos la arquitectura de la red\n",
    "\n",
    "<img src=\"files/test1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network size\n",
    "N_input = 4\n",
    "N_hidden = 3\n",
    "N_output = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir los pesos\n",
    "\n",
    "Recordemos que los pesos ahora los representamos con matrices\n",
    "\n",
    "$$W = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2}\n",
    " \\\\\n",
    "w_{2,1} & w_{2,2}\n",
    " \\\\\n",
    "w_{3,1} & w_{3,2}\n",
    " \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "donde los renglones se relacionan con las entradas y las columnas con los nodos intermedios. Y las entradas son\n",
    "\n",
    "$$ X = \\begin{bmatrix} x_1 & x_2 & x_3 \\end{bmatrix} $$\n",
    "\n",
    "Como herramienta usaremos:\n",
    "\n",
    "> numpy.random.normal(loc=0.0, scale=1.0, size=None)\n",
    "\n",
    "*Draw random samples from a normal (Gaussian) distribution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.0\n",
    "stdev = 0.1\n",
    "\n",
    "weights_input_to_hidden = np.random.normal(mean, scale=stdev, size=(N_input, N_hidden))\n",
    "weights_hidden_to_output = np.random.normal(mean, scale=stdev, size=(N_hidden, N_output))\n",
    "\n",
    "# Make some fake data\n",
    "X = np.random.randn(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular la salida\n",
    "\n",
    "Recordemos de la lección que\n",
    "\n",
    "$$ H = X W $$\n",
    "\n",
    "$$ y = f(H) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden-layer Output:\n",
      "[0.48975306 0.54204203 0.4790029 ]\n",
      "Output-layer Output:\n",
      "[0.46750523 0.47274472]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_in = np.dot(X, weights_input_to_hidden)\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "\n",
    "print('Hidden-layer Output:')\n",
    "print(hidden_layer_out)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_out, weights_hidden_to_output)\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "\n",
    "print('Output-layer Output:')\n",
    "print(output_layer_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
