{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descenso por gradiente completo\n",
    "\n",
    "(Ejercicio, 3 puntos posibles)\n",
    "\n",
    "El método de descenso por gradiente es una técnica de optimización utilizada para encontrar el mínimo de una función. Consiste en iterativamente ajustar los parámetros de la función en la dirección opuesta al gradiente de la función de pérdida, multiplicado por una tasa de aprendizaje. Esto permite que los parámetros converjan hacia los valores que minimizan la función de pérdida, lo que es crucial en el entrenamiento de modelos de aprendizaje automático como redes neuronales, donde se busca minimizar el error entre las predicciones del modelo y los valores reales.\n",
    "\n",
    "En este notebook implementaremos el algoritmo completo de descenso por gradiente. Para validar que funciona al final lo probaremos en el entrenamiento de una red neuronal simple. Usaremos como conjunto de datos que esta incluído en el archivo data.csv. \n",
    "\n",
    "@juan1rving\n",
    "\n",
    "Nota: Este notebook requiere que copies los archivos requeridos antes de usar en Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos los paquete necesarios\n",
    "import numpy as np\n",
    "import nni\n",
    "\n",
    "# cargamos datos de ejemplo\n",
    "from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# En este ejercicio por propósitos de analizar las salidas utilizaremos la misma semilla para los números aleatorios.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización de los pesos\n",
    "\n",
    "En un principio no queremos tener todos los pesos en cero porque esto generaría en la salida una predicción nula. Por lo tanto, asignaremos los pesos iniciales de forma aleatoria y cercanos a cero. Otra recomendación es escalar los valores aleatorios es dependencia del número de entradas del nodo (n).\n",
    "\n",
    "$$w = rand(1,\\frac{1}{\\sqrt{n}})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights. \n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "bias = np.zeros(1)\n",
    "\n",
    "# Definimos la neurona\n",
    "from nni.models import Neurona\n",
    "from nni.functions import sigmoid\n",
    "\n",
    "nodo = Neurona(weights, bias, nni.functions.sigmoid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Exactitud = \\frac{\\# aciertos}{\\# predicciones} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probemos la exactitud de la red antes de entrenarla\n",
    "test_out = nodo.forward(features_test)\n",
    "predictions = test_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Exactitud: {:.3f}\".format(accuracy))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros\n",
    "\n",
    "Los hiperpámetros de la red indican el números de veces que itera el método (épocas-epochs), la taza de aprendizaje (learning rate).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# número de épocas\n",
    "epochs = 5\n",
    "\n",
    "# tasa de aprendizaje\n",
    "learnrate = 0.0001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso por gradiente completo.\n",
    "\n",
    "El algoritmo de descenso por gradiente de forma iterativa cambia el valor de los pesos de tal forma que se disminuya el error. \n",
    "\n",
    "<img src=\"files/despg.png\">\n",
    "\n",
    "En la siguiete celda encontrarás la plantilla del algoritmo. Tu misión, si decides aceptarla, es completar el código faltante para que funcione el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO (1 punto): Completa el código faltante\n",
    "\n",
    "# Variable para registrar el rendimiento\n",
    "History_loss = []\n",
    "\n",
    "# Algoritmo descenso por gradiente\n",
    "for e in range(epochs):\n",
    "    incremento_w = np.zeros(weights.shape)\n",
    "    # Para todos los renglones de ejemplo, asignar a x la entrada, y a y la salida deseada\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # TODO: calcula la predicción de la red\n",
    "        output = None\n",
    "\n",
    "        # TODO: calcula el término de error\n",
    "        error_term = None\n",
    "\n",
    "        # TODO: calcula el incremento\n",
    "        incremento_w += error_term * x\n",
    "\n",
    "    # TODO: Actualiza los pesos\n",
    "    weights += None\n",
    "    nodo.weights = weights\n",
    "\n",
    "    # Ahora calculemos el error en el conjunto de datos de entrenamiento para registro y visualización\n",
    "    out = nodo.forward(features.values)\n",
    "    loss = np.mean((out - targets) ** 2)    \n",
    "    History_loss.append(loss)\n",
    "    if e % (epochs / 10) == 0:\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Prueba distintas cantidades de épocas y visualiza el resultado. Puedes usar los valores almacenados en el historial de la perdida. Si es que tu método esta entrenando bien el resultado deberá graficarse como la siguiente figura.\n",
    "\n",
    "<img src=\"files/train.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica el error conforme avanzaron las épocas del entrenamiento.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(History_loss)\n",
    "plt.title(\"Error durante el entrenamiento\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluemos la exactitud de la red\n",
    "\n",
    "Validar una red neuronal es crucial porque permite evaluar su rendimiento en datos independientes, verificando su capacidad para generalizar patrones aprendidos durante el entrenamiento. Mientras que el entrenamiento adapta los pesos de la red para minimizar el error en los datos de entrenamiento, la validación revela si el modelo puede hacer predicciones precisas en datos nuevos. Este proceso ayuda a detectar problemas de sobreajuste o subajuste, garantizando así que la red pueda desempeñarse de manera efectiva en situaciones del mundo real y proporcionar resultados confiables y útiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de la exactitud\n",
    "\n",
    "test_out = nodo.forward(features_test)\n",
    "predictions = test_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que tan bien te fue en los resultados? Seguramente bien. Si logras un accuracy de más del 0.74 entonces alcanzas 2 puntos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbad788490f55b163920bee5e9d5e0cba00db5905dc94f4bdbe0011e55bf465f"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
